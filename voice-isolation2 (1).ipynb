{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:39:05.885691Z","iopub.execute_input":"2025-06-24T17:39:05.885971Z","iopub.status.idle":"2025-06-24T17:39:05.891476Z","shell.execute_reply.started":"2025-06-24T17:39:05.885952Z","shell.execute_reply":"2025-06-24T17:39:05.890769Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import layers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T17:39:06.697260Z","iopub.execute_input":"2025-06-24T17:39:06.697548Z","iopub.status.idle":"2025-06-24T17:39:06.701696Z","shell.execute_reply.started":"2025-06-24T17:39:06.697528Z","shell.execute_reply":"2025-06-24T17:39:06.700783Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class complexConv2D(layers.Layer):\n    def __init__(self, filters, kernel_size, strides=(1, 1), padding='same'):\n        super(complexConv2D, self).__init__()\n        self.filters = filters\n        self.kernel_size = kernel_size\n        self.strides = strides\n        self.padding = padding\n\n        self.real_conv2D = layers.Conv2D(filters, kernel_size, strides = strides, padding = padding)\n        self.complex_conv2D = layers.Conv2D(filters, kernel_size, strides = strides, padding = padding)\n\n    def call(self, input_stft):\n        real_stft, img_stft = tf.split(input_stft, axis=-1)\n\n        real_stft_real = self.real_conv2D(real_stft)\n        real_stft_img = self.complex_conv2D(real_stft)\n\n        img_stft_real = self.real_conv2D(img_stft)\n        img_stft_img = self.complex_conv2D(img_stft)\n\n        output_real = real_stft_real - img_stft_img\n        output_img = real_stft_img + img_stft_real\n\n        return tf.stack([output_real, output_img], axis=-1)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:40.929785Z","iopub.execute_input":"2025-06-24T18:12:40.930035Z","iopub.status.idle":"2025-06-24T18:12:40.935993Z","shell.execute_reply.started":"2025-06-24T18:12:40.930017Z","shell.execute_reply":"2025-06-24T18:12:40.935121Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class complexBN_PReLu(layers.Layer):\n    def __init__(self):\n        super(complexBN_PReLu, self).__init__()\n        self.real_bn = layers.BatchNormalization()\n        self.img_bn = layers.BatchNormalization()\n        self.real_prelu = layers.PReLU()\n        self.img_prelu = layers.PReLU()\n\n\n    def call(self, inputs):\n        real, img = tf.split(inputs, 2, axis=-1)\n\n        real = self.real_bn(real)\n        img = self.img_bn(img)\n\n        real = self.real_prelu(real)\n        img = self.img_prelu(img)\n\n        return tf.stack([real, img], axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:41.244682Z","iopub.execute_input":"2025-06-24T18:12:41.244973Z","iopub.status.idle":"2025-06-24T18:12:41.250990Z","shell.execute_reply.started":"2025-06-24T18:12:41.244952Z","shell.execute_reply":"2025-06-24T18:12:41.250287Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"class complexEncodeBlock(layers.Layer):\n    def __init__(self, filters, kernel_size=(3,3), strides=(1,1)):\n        super(complexEncodeBlock, self).__init__()\n        self.conv = complexConv2D(filters, kernel_size, strides=strides)\n        self.bn_prelu = complexBN_PReLu()\n\n    def call(self, inputs):\n        x = self.conv(inputs)\n        x = self.bn_prelu(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:41.556557Z","iopub.execute_input":"2025-06-24T18:12:41.556882Z","iopub.status.idle":"2025-06-24T18:12:41.563361Z","shell.execute_reply.started":"2025-06-24T18:12:41.556861Z","shell.execute_reply":"2025-06-24T18:12:41.562227Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"class complexLSTM(layers.Layer):\n    def __init__(self, unit):\n        super(complexLSTM, self).__init__()\n        self.real_lstm = layers.LSTM(unit, return_sequences=True)\n        self.img_lstm = layers.LSTM(unit, return_sequences=True)\n\n    def call(self, inputs):\n        B, T, F, C = inputs.shape\n        r,img = tf.split(inputs, 2, axis=-1)\n\n        r = tf.reshape(r, (B, T, -1))\n        img = tf.reshape(img, (B, T, -1))\n\n        Frr = self.real_lstm(r)\n        Fir = self.real_lstm(img)\n        Fri = self.img_lstm(r)\n        Fii = self.img_lstm(img)\n\n        out_real = Frr - Fii\n        out_img = Fri + Fir\n        \n        F_dim = out_real.shape[-1]\n        out_real = tf.reshape(out_real, (B, T, F_dim//2, 1))\n        out_img = tf.reshape(out_img, (B, T, F_dim//2, 1))\n\n        return tf.stack([out_real, out_img], axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:41.794392Z","iopub.execute_input":"2025-06-24T18:12:41.794710Z","iopub.status.idle":"2025-06-24T18:12:41.800921Z","shell.execute_reply.started":"2025-06-24T18:12:41.794689Z","shell.execute_reply":"2025-06-24T18:12:41.800030Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"class complexDeconv2D(layers.Layer):\n    def __init__(self, filters, kernel_size, strides=(2,2), padding='same'):\n        super(complexDeconv2D, self).__init__()\n\n        self.real_deconv = layers.Conv2DTranspose(filters, kernel_size, strides, padding)\n        self.img_deconv = layers.Conv2DTranspose(filters, kernel_size, strides, padding)\n\n    def call(self, inputs):\n        real, img = tf.spkit(inuts, 2, axis=-1)\n\n        real_stft_real = self.real_deconv(real)\n        real_stft_img = self.img_deconv(real)\n\n        img_stft_real = self.real_deconv(img)\n        img_stft_img = self.img_deconv(img)\n\n        output_real = real_stft_real - img_stft_img\n        output_img = real_stft_img + img_stft_real\n\n        return tf.stack([output_real, output_img], axis=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:42.051180Z","iopub.execute_input":"2025-06-24T18:12:42.051474Z","iopub.status.idle":"2025-06-24T18:12:42.057653Z","shell.execute_reply.started":"2025-06-24T18:12:42.051455Z","shell.execute_reply":"2025-06-24T18:12:42.056454Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"class complexDecoderBlock(layers.Layer):\n    def __init__(self, filters, kernel_size=(3,3), strides=(2,2)):\n        super(complexDecoderBlock, self).__init__()\n        self.deconv = complexDeconv2D(filters, kernel_size, strides)\n        self.batchNormActivation = complexBN_PReLu()\n\n    def call(self, x, skip):\n        x = tf.stack([x, skip], axis=-1)\n        x = self.deconv(x)\n        x = self.batchNormActivation(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:42.274748Z","iopub.execute_input":"2025-06-24T18:12:42.275029Z","iopub.status.idle":"2025-06-24T18:12:42.280889Z","shell.execute_reply.started":"2025-06-24T18:12:42.275007Z","shell.execute_reply":"2025-06-24T18:12:42.279856Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def dccrnModel(input_shape=(282, 256, 2)):\n    inputs = tf.keras.Input(shape = input_shape)\n    x = inputs\n    skips = []\n\n    for filters in [32, 64, 128, 256, 256]:\n        x = complexEncodeBlock(filters)(x)\n        skips.append(x)\n\n    x = complexLSTM(unit = 256)(x)\n\n    for i, filters in enumerate([256, 256, 128, 64, 32]):\n        skip = skips[-(i+1)]\n        x = complexDecoderBlock(filters)(x, skip)\n\n    output = complexConv2D(filters = 1, kernel_size=(1,1))(x)\n    return tf.keras.Model(inputs=inputs, outputs=output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:42.464544Z","iopub.execute_input":"2025-06-24T18:12:42.464867Z","iopub.status.idle":"2025-06-24T18:12:42.470833Z","shell.execute_reply.started":"2025-06-24T18:12:42.464847Z","shell.execute_reply":"2025-06-24T18:12:42.469763Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"model = dccrnModel()\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T18:12:46.882075Z","iopub.execute_input":"2025-06-24T18:12:46.882404Z","iopub.status.idle":"2025-06-24T18:12:46.938382Z","shell.execute_reply.started":"2025-06-24T18:12:46.882359Z","shell.execute_reply":"2025-06-24T18:12:46.936952Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:1387: UserWarning: Layer 'complex_encode_block_2' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\nException encountered: ''Exception encountered when calling complexConv2D.call().\n\n\u001b[1mMissing required positional argument\u001b[0m\n\nArguments received by complexConv2D.call():\n  • input_stft=tf.Tensor(shape=(None, 282, 256, 2), dtype=float32)''\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'complex_encode_block_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1259415759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdccrnModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/4174318567.py\u001b[0m in \u001b[0;36mdccrnModel\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplexEncodeBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mskips\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/3495325582.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_prelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/2182039887.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_stft)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_stft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mreal_stft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_stft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mreal_stft_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_conv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_stft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling complexEncodeBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'complex_encode_block_2' (of type complexEncodeBlock). Either the `complexEncodeBlock.call()` method is incorrect, or you need to implement the `complexEncodeBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling complexConv2D.call().\n\n\u001b[1mMissing required positional argument\u001b[0m\n\nArguments received by complexConv2D.call():\n  • input_stft=tf.Tensor(shape=(None, 282, 256, 2), dtype=float32)\u001b[0m\n\nArguments received by complexEncodeBlock.call():\n  • args=('<KerasTensor shape=(None, 282, 256, 2), dtype=float32, sparse=False, name=keras_tensor_2>',)\n  • kwargs=<class 'inspect._empty'>"],"ename":"TypeError","evalue":"Exception encountered when calling complexEncodeBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'complex_encode_block_2' (of type complexEncodeBlock). Either the `complexEncodeBlock.call()` method is incorrect, or you need to implement the `complexEncodeBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling complexConv2D.call().\n\n\u001b[1mMissing required positional argument\u001b[0m\n\nArguments received by complexConv2D.call():\n  • input_stft=tf.Tensor(shape=(None, 282, 256, 2), dtype=float32)\u001b[0m\n\nArguments received by complexEncodeBlock.call():\n  • args=('<KerasTensor shape=(None, 282, 256, 2), dtype=float32, sparse=False, name=keras_tensor_2>',)\n  • kwargs=<class 'inspect._empty'>","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}